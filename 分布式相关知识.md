
### 一、基础组件

#### 1.1 Zookeeper(分布式裁判员)：
Zookeeper(分布式裁判员)：
分布式环境中的集群管理、分布式锁、Master选举的场景的问题，作为一个分布式的中间件而存在，他是一个分布式开源的协调组件。
1. 集群管理：保证每个节点都需要是最新的数据。通过调用sync来同步，是顺序一致性的模型。
2. 分布式锁：贡献资源的并发安全性，跨进程的锁，也就是分布式锁来实现。提供了多种不同的节点，例如持久化节点，临时节点，即有序节点，容器节点等。利用有序性和同一个节点的唯一性来实现。
3. master选举：master（负责数据的读写操作）和slave（只负责数据的读操作），如何确定某个节点是master和slave也是一个难点，利用持久化的节点和有序性来实现master选举。
4. 总结：一个经典的分布式数据一致性解决方案。高性能，高可用，提供保证访问顺序的一些能力模型。
5. 用处：kafka，hadoop，hbase等都是利用这个来实现的。


#### 1.2 Spark
spark：主流的大数据计算框架，相比Hadoop的MapReduce有近百倍的性能提升。衍生出了spark sql，流计算，图计算和机器学习等计算框架
1. 基本概念：
  a. Application：整个计算任务
  b. Job：collect和save等算子来将application划分成多个job
  c. Stage：例如shuffle算子将job划分成多个stage
  d. Task：最小的计算单元
2. 系统运行架构：
  a. Driver：运行一个任务是会生成，他会向cluster manager申请资源，申请完后会注册到Driver
  b. Master
  c. Cluster Manager：协调多个Worker去申请资源
  d. Worker
  e. Executor
3. RDD弹性分布式数据集（Resilient distributed Datasets）： 代码中的每个数据是划分多个分区存在多个节点上的，满足分布式的需求。只能从HDFS来读取或者经过RDD来生成。延时计算，遇到actions算子才真正的计算。
4. action
5. stage
6. shuffle的概念：经过算子的时候，不得不经过重新分区才能得到结果，称这样的算子为shuffle算子，RDD三个分区->key相同的合并到同一个分区，常见的shuffle算子有JOIN，groupby，reduceByKey，countByKey算子等