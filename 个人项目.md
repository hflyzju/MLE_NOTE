

### 一、搜索引擎扩召回

工作  ：
1. 负责研究query rewrite算法，提升搜狗搜索引擎自制医疗百科内容的召回率。

#### 背景：
当用户在互联网上表达需求时候，有成千上万种不同表现形式，我这边的主要工作是研究query rewrite算法来提升搜狗搜索引擎上相关卡片的召回率。将算法部署到生产环境后，我的模型服务每天处理了超过亿级别的query，并且回答了200万的量级的问题，在精度95%的情况下，召回率提升21%+（66%->80%），延时在15毫秒以内。

例如：
hi 天猫精灵->给我放一首周杰伦的歌
hi 天猫精灵->放一首周董的歌
听歌的时候，这里就有有很多种表达，期望准确识别其意图，并给用户提供相关内容。

#### 难点：
  1. 语义gap：成千上万的表达方式去表达同一个意思，放一首歌，来一首歌，给我来一首歌曲。
  2. 实体gap，实体词有很多同义词。 周董的歌 vs 周杰伦的歌。
  4. 精度要求非常高。
  5. 延时要求非常高，我们需要在毫秒级别时间内作出反应。
  6. 线上流量长尾分布现象比较明显，处理好30%的常见回答我们可能就能回答70%流量的问题了，但是剩下的长尾优化非常困难。

#### 我是怎么做的：
1. 总体方法：
  1.1 收集已经能正确回答的query，我们named vrq，将线上query改写成vrq，来提升相关内容召回率。
  1.2 实现了一种在线：基于槽位+文本检索，离线：文本生成的方式

如何解决上述难点和挑战的呢？

2. 如何提升语义gap泛化能力：

  2.1. 这里搭建了一套召回，语义判别的框架，来提升语义泛化能力，这里召回模型召回top10的候选，来提高召回率，后面通过一个语义判别模型来提高精度。

  2.2. 具体做法是，首先基于vrq构建检索库，当遇到一个query，将其embeding成向量，利用向量检索引擎faiss召回top10的候选query，然后用一个语义判别模型来判断是否可以成功改写。

3. 如何提升实体gap泛化能力：

  3.1 实体识别算法识别实体词，例如人名，歌名等，然后将实体词linking到标准实体上面，来提升实体层面的泛化能力。

4. 如何保证精度：

  4.1 将语义gap分词实体gap，问法gap进行处理，分两阶段，相当于降低难度，提高精度，召回阶段提升明显。
  4.2 预训练阶段，引入额外医疗实体知识，同义词知识，对全词进行mask，来提高精度
  4.3 利用seq2seq模型，迭代语义判别模型，生成更多数据，提高精度。
  4.4 利用模型修正标注数据，迭代3轮，效果提升明显。
  4.5 引入实体的信息，有些信息是实体相关的。
  4.6 取得了95%的上线精度。

5. 如何保证低延时要求
  4.1 高频问题：当命中槽位pattern时候，直接返回结果。
  4.2 中低频问题：1. 通过将实体mask后在构建索引，减少检索库的数量。 2. 利用faiss检索加速检索，提高召回速度。
  4.3 中低频问题：利用seq2seq模型生成同义query，挖掘候选query，并将它补充到索引库里面，来提高速度。
  4.5 最终模型的平均耗时在15毫秒以内。


#### 技术点

1. ner+linking有什么方法？
   1. ner建模方法：bert，bert+crf，mrc，global pointer方法，prompt方法。
   2. crf：这就是逐帧 softmax 和 CRF 的根本不同了：前者将序列标注看成是 n 个 k 分类问题，后者将序列标注看成是 1 个 [公式] 分类问题。
   3. crf包括发射矩阵和转移矩阵，转移矩阵是tag_num*tag_num的一个可训练的矩阵。维特比算法。每个时间步只选择得分最高的那条路径继续下一个时间步。
   4. crf相关资料1：https://zhuanlan.zhihu.com/p/37163081
   5. crf相关资料2：每个时间步只选择得分最高的那条路径继续下一个时间步。
   6. mrc：预测起始位置，
   7. mrc解读：https://blog.csdn.net/qq_16949707/article/details/115517783?spm=1001.2014.3001.5501
   8. mrc代码解读：https://blog.csdn.net/qq_16949707/article/details/117534533
   9. mrc解读：https://mp.weixin.qq.com/s/aYYUAhfiGYegDQ8qHMBCpw

2. 文本向量检索是怎么做的？
   1. 评估方法有哪些？
   2. 怎么构建数据集来提升embedding能力？
3. 向量检索引擎的原理？
4. 文本生成是怎么做的？
5. 模型蒸馏是怎么做的？