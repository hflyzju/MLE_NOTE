

### 一、搜索引擎扩召回

工作  ：
1. 负责研究query rewrite算法，提升搜狗搜索引擎自制医疗百科内容的召回率。

#### 背景：
当用户在互联网上表达需求时候，有成千上万种不同表现形式，我这边的主要工作是研究query rewrite算法来提升搜狗搜索引擎上相关卡片的召回率。将算法部署到生产环境后，我的模型服务每天处理了超过亿级别的query，并且回答了200万的量级的问题，在精度95%的情况下，召回率提升21%+（66%->80%），延时在15毫秒以内。

例如：
hi 天猫精灵->给我放一首周杰伦的歌
hi 天猫精灵->放一首周董的歌
听歌的时候，这里就有有很多种表达，期望准确识别其意图，并给用户提供相关内容。

#### 难点：
  1. 语义gap：成千上万的表达方式去表达同一个意思，放一首歌，来一首歌，给我来一首歌曲。
  2. 实体gap，实体词有很多同义词。 周董的歌 vs 周杰伦的歌。
  4. 精度要求非常高。
  5. 延时要求非常高，我们需要在毫秒级别时间内作出反应。
  6. 线上流量长尾分布现象比较明显，处理好30%的常见回答我们可能就能回答70%流量的问题了，但是剩下的长尾优化非常困难。

#### 我是怎么做的：
1. 总体方法：
  1.1 收集已经能正确回答的query，我们named vrq，将线上query改写成vrq，来提升相关内容召回率。
  1.2 实现了一种在线：基于槽位+文本检索，离线：文本生成的方式

如何解决上述难点和挑战的呢？

2. 如何提升语义gap泛化能力：

  2.1. 这里搭建了一套召回，语义判别的框架，来提升语义泛化能力，这里召回模型召回top10的候选，来提高召回率，后面通过一个语义判别模型来提高精度。

  2.2. 具体做法是，首先基于vrq构建检索库，当遇到一个query，将其embeding成向量，利用向量检索引擎faiss召回top10的候选query，然后用一个语义判别模型来判断是否可以成功改写。

3. 如何提升实体gap泛化能力：

  3.1 实体识别算法识别实体词，例如人名，歌名等，然后将实体词linking到标准实体上面，来提升实体层面的泛化能力。

4. 如何保证精度：

  4.1 将语义gap分词实体gap，问法gap进行处理，分两阶段，相当于降低难度，提高精度，召回阶段提升明显。
  4.2 预训练阶段，引入额外医疗实体知识，同义词知识，对全词进行mask，来提高精度
  4.3 利用seq2seq模型，迭代语义判别模型，生成更多数据，提高精度。
  4.4 利用模型修正标注数据，迭代3轮，效果提升明显。
  4.5 引入实体的信息，有些信息是实体相关的。
  4.6 取得了95%的上线精度。

5. 如何保证低延时要求
  4.1 高频问题：当命中槽位pattern时候，直接返回结果。
  4.2 中低频问题：1. 通过将实体mask后在构建索引，减少检索库的数量。 2. 利用faiss检索加速检索，提高召回速度。
  4.3 中低频问题：利用seq2seq模型生成同义query，挖掘候选query，并将它补充到索引库里面，来提高速度。
  4.5 最终模型的平均耗时在15毫秒以内。


#### 技术点

1. ner+linking有什么方法？
   1. ner建模方法：bert，bert+crf，mrc，global pointer方法，prompt方法。
   2. crf：这就是逐帧 softmax 和 CRF 的根本不同了：前者将序列标注看成是 n 个 k 分类问题，后者将序列标注看成是 1 个 [公式] 分类问题。
   3. crf包括发射矩阵和转移矩阵，转移矩阵是tag_num*tag_num的一个可训练的矩阵。维特比算法。每个时间步只选择得分最高的那条路径继续下一个时间步。
   4. crf相关资料1：https://zhuanlan.zhihu.com/p/37163081
   5. crf相关资料2：每个时间步只选择得分最高的那条路径继续下一个时间步。
   6. mrc：预测起始位置，start和end，采用的是交叉熵
   7. mrc解读：https://blog.csdn.net/qq_16949707/article/details/115517783?spm=1001.2014.3001.5501
   8. mrc代码解读：https://blog.csdn.net/qq_16949707/article/details/117534533
   9. mrc解读：https://mp.weixin.qq.com/s/aYYUAhfiGYegDQ8qHMBCpw

2. 文本向量检索是怎么做的？
   1. 评估方法有哪些？pearson相关性：两定量满足正态分布时采用这个。 Spearman相关系数：从小到大排序，秩次用Rx，Ry，平均秩次为每个数据的秩次，rs=sum(Rx-Rx_mean)(Ry-Ry_mean)/sqrt(sum(Rx-Rx_mean)^2 * sum(Ry-Ry_mean)^2)，与pearson相关系数的不同只是将X，Y替换成了Rx，Ry。
   2. 怎么构建数据集来提升embedding能力？
   3. simCSE, 无监督loss：-log(e^(sim(hi, hi') / sum_e^sim(hi, hj)))
   4. simCSE, 有监督loss:-log(e^sim(hi,hi+) / sum_[e^sim(hi,hj+)/t + e^sim(hi,hj-)/t])
   5. sbert双塔模型：pooling采用mean效果最好，（u，v，｜u-v｜）作为softmax分类的特征，做inference的时候，还是拿mean之后的向量做相似度计算。
   6. EsimCSE会倾向于同样长度的句子相似度更高，用repetition的方式来生产positive pair。

3. 向量检索引擎的原理？
   1. 度量方式：欧氏距离，cos距离，汉明距离，jaccard相似度
   2. 基于空间划分：乘积向量化 hash，基于树的方法，例如KDTree，方差最大的纬度进行分裂。 基于hash，局部敏感hash。乘积量化（倒排）：核心思想是分段和聚类，先划分空间，然后在空间内进行聚类。
   3. 基于图：HNSW：构建：逐个插入顶点，找到与顶点最近的m个顶点，将新的顶点与他们连起来形成边。 查找：查找绿色的另据顶点，通过高速公路来加速。可能会导致先加入的点，基本都比较远。HNSW采用分层插入的原理，拆入的时候layer=0，插入所有点，layer=1插入上一层的50%，以此内推。 查询的时候，从最后一层开始查找，这样来加速。

4. 文本生成是怎么做的？
   1. 通用领域43.7w文档问题对（好搜集），可以显著提升生成问题的流畅度。
   2. MRC数据：训练集14201个文档，包含4.7w个问题及其答案，测试集合2507个文档，包括8112个问题和答案。
   3. 模型：文档作为s1，问题作为s2送入unilm-seq2seq模型，使用常规的交叉熵作为损失函数。
   4. inference过程，采用Nucleus采样生成问题。
   5. 如何解码：ICLR，beam search总会选择最符合语言模型的词汇，生产的文本没有新意，topk sample：采样优化：一定几率不选择最大概率的，从前k个概率最大的词中，按照他们的概率进行采样，优点：不会每次都概率最大，缺点：k的选择比较困难，可能会出现长尾词或者不通顺的现象。Nucleus sample：解决了这个问题：给定一个概率阈值p，从解码词中选择一个最小集vp，使他们呢出现的概率大于等于p，然后再对vp做一次re-scaling，本时间步仅从vp集合中解码，好处：随着解码词概率分布不同，候选词集合大小会动态变化，同时解码词还是从头部筛选，可以在满足多样性的同时又保证通顺。Temperature sampling：直接re-scale原有的解码词分布，参考：https://zhuanlan.zhihu.com/p/442557114
   6.beamsearch：开始选择k个，然后生成第二个词的时候，将当前序列分别与词表的词组合，得到k*v个序列，然后从中选择3个概率最大的作为结果，一直直到结束。贪心解码相当于B=1的情况，每次只选择概率最大的词。维特比算法：从开始状态后的每一步，记录到达该状态的所有路径的概率最大值，以此作为基准继续向后推进。如果这个最大值都不能使该状态成为最大思然状态路径上的节点的话，那么小于他概率的值就更没有可能了。
   7. beam search vs viterbi算法，beam search是对状态转移的路径进行剪枝，viterbi是合并不同路径到达同一状态的概率值，用最大值作为该状态的充分估计值，从而在后续计算中，忽略历史信息，达到剪枝的目的。Beam search是空间剪枝，viterbi是时间剪枝。

5. 模型蒸馏是怎么做的？



实体链接难点：
1. 用户表述复杂，相似症状多，标准症状粒度细：例如换牙期牙齿掉了三个月还没长新牙 -> 牙齿萌出延迟
2. 一个症状包括多个标准症状：脑袋和肚子都有点疼 -> 头疼，腹疼
3. 症状表述存在长远以来，冗余信息多：肚子像来月经一样疼但是没来月经 -> 腹疼

解决方案：
1. cos相似度匹配，tfidf+医疗特征计算在哭的症状词和当前症状的相似度。
2. 精排序模块，采用listwise方案，对cos相似度排序的前5进行重排序
3. 症状部位+症状表现组合匹配，解决场症状描述，忽略无用特征引入的歧义。
4. 黑名单过滤